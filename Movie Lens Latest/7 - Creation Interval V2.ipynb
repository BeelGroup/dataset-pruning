{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Intervals, second method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the first methode we based the creation of the interval on the global review number. If an user have 21 review in the the dataset we will be in the interval 20-29. But in this second method we only care about the number of review in the trainig dataset, if an user have 21 ratings he will probably have 17 review in the training dataset and 4 in the testing dataset then he should go in the interval 10-19 and not 20-29."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be sure of the separation we did it user by user, because for users who don't have a lot of review, especialy between 1 and 10, a global separtation will pose problem. An User who have 2 review can have the both review in the training or the testing dataset and we expecte one in th trainig and one inthe testing in that case. Then we do the separation differently for each number of review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second problem is that I want to do some cross validation to improve the results and that will make things more difficult, beacause evry part of the dataset should be test two time, we want 80% in the training dataset and 20% in the testing dataset and we will do 10 folds of cross validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the user who have a number of rating between 1 and 10, we will take only one ratings for the testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os.path\n",
    "import os\n",
    "from random import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>48587.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>48587.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>48587.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48587.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>48587.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    userId  movieId  rating\n",
       "0  48587.0      1.0     3.0\n",
       "1  48587.0      4.0     2.0\n",
       "2  48587.0     22.0     3.0\n",
       "3  48587.0     24.0     3.0\n",
       "4  48587.0     25.0     3.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_parquet('data/ratings.gzip')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ar=df.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6858421"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inteName2(i):\n",
    "    if i==0:\n",
    "        return \"1-9\"\n",
    "    elif i<10:\n",
    "        return str(int(i*10))+\"-\"+str(int(i*10+9))\n",
    "    elif i>=50:\n",
    "        return 'sup500'\n",
    "    else :\n",
    "        return str(int(i*10))+\"-\"+str(int(i*10+49))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inteName(i):\n",
    "    if i==0:\n",
    "        return \"1-9\"\n",
    "    else :\n",
    "        return str(int(i*10))+\"-\"+str(int(i*10+9))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function return the last line such as the userId is the same as the line l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nextUser(ar,l):\n",
    "    userID=ar[l,0]\n",
    "    t=len(ar)\n",
    "    nxt=l+1\n",
    "    while((nxt<t)and(ar[nxt,0]==userID)):\n",
    "        nxt+=1\n",
    "    return nxt-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function return the list of review which will be in each testing dataset for each fold of the cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def listInteTestInf10(l):\n",
    "    listInte=list()\n",
    "    size=len(l)\n",
    "    cpt=0\n",
    "    \n",
    "    if size ==10:\n",
    "        for i in range(size):\n",
    "            listInte.append(l[i])\n",
    "            shuffle(listInte)\n",
    "        return listInte\n",
    "    \n",
    "    while (cpt+size<10) :\n",
    "        for i in range(size):\n",
    "            listInte.append(l[i])\n",
    "            cpt+=1\n",
    "    if cpt!=10:\n",
    "        for i in range(10-cpt):\n",
    "            listInte.append(l[randint(0, size-1)])\n",
    "    shuffle(listInte)\n",
    "    return listInte"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function return the list of list of review which will be in each testing dataset for each fold of the cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def listInteTestSup10(l):\n",
    "    listInte=list()\n",
    "    size=len(l)\n",
    "    nbLine=size//5\n",
    "    for turn in range(2):\n",
    "        l2=l.copy()\n",
    "        shuffle(l2)\n",
    "        for i in range(4):\n",
    "            \n",
    "            lTemp=list()\n",
    "            for k in range(nbLine):\n",
    "                lTemp.append(l2[0])\n",
    "                del l2[0]\n",
    "            listInte.append(lTemp)\n",
    "        listInte.append(l2)\n",
    "    return listInte"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this fuction add all the review of the user who have all there ratings between start and end. Each line will be add in the good testing dataset and the good trainig dataset for each fold of the cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def listAppend(start,end):\n",
    "    sizeInte=end-start+1\n",
    "    inte=list()\n",
    "    for i in range(start,end+1):\n",
    "        inte.append(i)\n",
    "    \n",
    "    \n",
    "    if sizeInte<=10 :\n",
    "        lTest=listInteTestInf10(inte)\n",
    "        for fold in range(10) :\n",
    "            dicoNb[fold][ar[start,0]]=(sizeInte-1,1)\n",
    "            t=lTest[fold]\n",
    "            for l in inte:\n",
    "                if l==t :\n",
    "                    dicoTest[fold].append(l)\n",
    "                else :\n",
    "                    dicoTrain[fold].append(l)\n",
    "    \n",
    "    else :\n",
    "        lTest=listInteTestSup10(inte)\n",
    "        for fold in range(10) :\n",
    "            t=lTest[fold]\n",
    "            dicoNb[fold][ar[start,0]]=(sizeInte-len(t),len(t))\n",
    "            for l in inte :\n",
    "                if l in t :\n",
    "                    dicoTest[fold].append(l)\n",
    "                else :\n",
    "                    dicoTrain[fold].append(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part of the code create all the list of array which will be use to create all the dataset, we put them in a dictionary. We also record the number of review for each user. All user who have only one review are put in a diffrent dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lastLine=len(df)-1\n",
    "start=0\n",
    "end=nextUser(ar,start)\n",
    "dicoTrain={}\n",
    "dicoTest={}\n",
    "dicoNb={}\n",
    "listOne=list()\n",
    "for fold in range(10):\n",
    "    dicoNb[fold]={}\n",
    "    dicoTrain[fold]=list()\n",
    "    dicoTest[fold]=list()\n",
    "    \n",
    "while (end!=lastLine):\n",
    "    if end!=start:\n",
    "        listAppend(start,end)\n",
    "    else :\n",
    "        listOne.append([ar[start]])\n",
    "    start=end+1\n",
    "    end=nextUser(ar,start)\n",
    "if end!=start:\n",
    "    listAppend(start,end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We save the dataset whith all the useer who have only one ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1402\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>124607.0</td>\n",
       "      <td>173145.0</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186665.0</td>\n",
       "      <td>455.0</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>49512.0</td>\n",
       "      <td>174055.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>262971.0</td>\n",
       "      <td>3263.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>204024.0</td>\n",
       "      <td>318.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     userId   movieId  rating\n",
       "0  124607.0  173145.0     4.5\n",
       "1  186665.0     455.0     3.5\n",
       "2   49512.0  174055.0     5.0\n",
       "3  262971.0    3263.0     4.0\n",
       "4  204024.0     318.0     4.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arOne=np.concatenate(listOne)\n",
    "dfOne=pd.DataFrame({'userId':arOne[:,0],'movieId':arOne[:,1],'rating':arOne[:,2]})\n",
    "dfOne.to_parquet('dataCV3/dfOne.gzip', compression='gzip',index=False)\n",
    "print(len(dfOne))\n",
    "dfOne.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "del listOne,arOne,dfOne"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We save the number of review for each user for each fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--== save nb ratings ==-- \n",
      "--== save nb ratings ==-- \n",
      "--== save nb ratings ==-- \n",
      "--== save nb ratings ==-- \n",
      "--== save nb ratings ==-- \n",
      "--== save nb ratings ==-- \n",
      "--== save nb ratings ==-- \n",
      "--== save nb ratings ==-- \n",
      "--== save nb ratings ==-- \n",
      "--== save nb ratings ==-- \n"
     ]
    }
   ],
   "source": [
    "for fold in range(10):\n",
    "    print(\"--== save nb ratings ==-- \")\n",
    "    ID=list(dicoNb[fold].keys())\n",
    "    nbTrain=list()\n",
    "    nbTest=list()\n",
    "    for i in ID:\n",
    "        (a,b)=dicoNb[fold][i]\n",
    "        nbTrain.append(a)\n",
    "        nbTest.append(b)\n",
    "    dfDico = pd.DataFrame({'userId' : ID, 'NBRatingTrain' : nbTrain,'NBRatingTest' : nbTest})\n",
    "    dfDico.to_csv('dataCV3/user-nbRating_fold_'+str(fold)+'.csv',index =False)\n",
    "    del ID,dfDico\n",
    "del dicoNb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create all the dataset and we save them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--==  0  ==-- \n",
      "create and save testing dataset\n",
      "create and save training dataset\n",
      "--==  1  ==-- \n",
      "create and save testing dataset\n",
      "create and save training dataset\n",
      "--==  2  ==-- \n",
      "create and save testing dataset\n",
      "create and save training dataset\n",
      "--==  3  ==-- \n",
      "create and save testing dataset\n",
      "create and save training dataset\n",
      "--==  4  ==-- \n",
      "create and save testing dataset\n",
      "create and save training dataset\n",
      "--==  5  ==-- \n",
      "create and save testing dataset\n",
      "create and save training dataset\n",
      "--==  6  ==-- \n",
      "create and save testing dataset\n",
      "create and save training dataset\n",
      "--==  7  ==-- \n",
      "create and save testing dataset\n",
      "create and save training dataset\n",
      "--==  8  ==-- \n",
      "create and save testing dataset\n",
      "create and save training dataset\n",
      "--==  9  ==-- \n",
      "create and save testing dataset\n",
      "create and save training dataset\n"
     ]
    }
   ],
   "source": [
    "for fold in range(10):\n",
    "    print(\"--== \",fold,\" ==-- \")\n",
    "    print(\"create and save testing dataset\")\n",
    "    ldf=list()\n",
    "    for l in dicoTest[fold]:\n",
    "        ldf.append([ar[l]])\n",
    "    arTest=np.concatenate(ldf)\n",
    "    dfTest=pd.DataFrame({'userId':arTest[:,0],'movieId':arTest[:,1],'rating':arTest[:,2]})\n",
    "    dfTest.to_parquet('dataCV3/dfTest_fold_'+str(fold)+'.gzip', compression='gzip',index=False)\n",
    "    del arTest,dfTest\n",
    "    \n",
    "    print(\"create and save training dataset\")\n",
    "    ldf=list()\n",
    "    for l in dicoTrain[fold]:\n",
    "        ldf.append([ar[l]])\n",
    "    arTrain=np.concatenate(ldf)\n",
    "    dfTrain=pd.DataFrame({'userId':arTrain[:,0],'movieId':arTrain[:,1],'rating':arTrain[:,2]})\n",
    "    dfTrain.to_parquet('dataCV3/dfTrain_fold_'+str(fold)+'.gzip', compression='gzip',index=False)\n",
    "    del arTrain,dfTrain\n",
    "del ldf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "del dicoTrain,dicoTest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create all the interval dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______________________________________________________________\n",
      "fold :  0\n",
      "load nb ratings\n",
      "load testing dataset\n",
      "Repartition Start\n",
      "Sauvegarde des intervalles\n",
      "Creation of the large intervalles\n",
      "Creation of the intervalle sup500\n",
      "Creation of the intervalle inf20\n",
      "Creation of the intervalle sup20\n",
      "______________________________________________________________\n",
      "fold :  1\n",
      "load nb ratings\n",
      "load testing dataset\n",
      "Repartition Start\n",
      "Sauvegarde des intervalles\n",
      "Creation of the large intervalles\n",
      "Creation of the intervalle sup500\n",
      "Creation of the intervalle inf20\n",
      "Creation of the intervalle sup20\n",
      "______________________________________________________________\n",
      "fold :  2\n",
      "load nb ratings\n",
      "load testing dataset\n",
      "Repartition Start\n",
      "Sauvegarde des intervalles\n",
      "Creation of the large intervalles\n",
      "Creation of the intervalle sup500\n",
      "Creation of the intervalle inf20\n",
      "Creation of the intervalle sup20\n",
      "______________________________________________________________\n",
      "fold :  3\n",
      "load nb ratings\n",
      "load testing dataset\n",
      "Repartition Start\n",
      "Sauvegarde des intervalles\n",
      "Creation of the large intervalles\n",
      "Creation of the intervalle sup500\n",
      "Creation of the intervalle inf20\n",
      "Creation of the intervalle sup20\n",
      "______________________________________________________________\n",
      "fold :  4\n",
      "load nb ratings\n",
      "load testing dataset\n",
      "Repartition Start\n",
      "Sauvegarde des intervalles\n",
      "Creation of the large intervalles\n",
      "Creation of the intervalle sup500\n",
      "Creation of the intervalle inf20\n",
      "Creation of the intervalle sup20\n",
      "______________________________________________________________\n",
      "fold :  5\n",
      "load nb ratings\n",
      "load testing dataset\n",
      "Repartition Start\n",
      "Sauvegarde des intervalles\n",
      "Creation of the large intervalles\n",
      "Creation of the intervalle sup500\n",
      "Creation of the intervalle inf20\n",
      "Creation of the intervalle sup20\n",
      "______________________________________________________________\n",
      "fold :  6\n",
      "load nb ratings\n",
      "load testing dataset\n",
      "Repartition Start\n",
      "Sauvegarde des intervalles\n",
      "Creation of the large intervalles\n",
      "Creation of the intervalle sup500\n",
      "Creation of the intervalle inf20\n",
      "Creation of the intervalle sup20\n",
      "______________________________________________________________\n",
      "fold :  7\n",
      "load nb ratings\n",
      "load testing dataset\n",
      "Repartition Start\n",
      "Sauvegarde des intervalles\n",
      "Creation of the large intervalles\n",
      "Creation of the intervalle sup500\n",
      "Creation of the intervalle inf20\n",
      "Creation of the intervalle sup20\n",
      "______________________________________________________________\n",
      "fold :  8\n",
      "load nb ratings\n",
      "load testing dataset\n",
      "Repartition Start\n",
      "Sauvegarde des intervalles\n",
      "Creation of the large intervalles\n",
      "Creation of the intervalle sup500\n",
      "Creation of the intervalle inf20\n",
      "Creation of the intervalle sup20\n",
      "______________________________________________________________\n",
      "fold :  9\n",
      "load nb ratings\n",
      "load testing dataset\n",
      "Repartition Start\n",
      "Sauvegarde des intervalles\n",
      "Creation of the large intervalles\n",
      "Creation of the intervalle sup500\n",
      "Creation of the intervalle inf20\n",
      "Creation of the intervalle sup20\n"
     ]
    }
   ],
   "source": [
    "for fold in range(10):\n",
    "    print(\"______________________________________________________________\")\n",
    "    print(\"fold : \",fold)\n",
    "    print(\"load nb ratings\")\n",
    "    arDico=pd.read_csv('dataCV3/user-nbRating_fold_'+str(fold)+'.csv').to_numpy()\n",
    "    d={}\n",
    "    for i in range(len(arDico)) :\n",
    "        d[arDico[i,0]]=arDico[i,1]\n",
    "    del arDico\n",
    "    \n",
    "    print(\"load testing dataset\")\n",
    "    arTest=pd.read_parquet('dataCV3/dfTest_fold_'+str(fold)+'.gzip').to_numpy()\n",
    "    size=len(arTest)\n",
    "    dicoDf={}\n",
    "    print(\"Repartition Start\")\n",
    "    for j in range(size): \n",
    "        nb=d[arTest[j,0]]//10\n",
    "        if nb in dicoDf :\n",
    "            dicoDf[nb].append([arTest[j]])\n",
    "        else:\n",
    "            dicoDf[nb]=list()\n",
    "            dicoDf[nb].append([arTest[j]])\n",
    "\n",
    "    print(\"Sauvegarde des intervalles\")\n",
    "    for j in dicoDf:\n",
    "        a=np.concatenate(dicoDf[j],axis=0)\n",
    "        dfTemp = pd.DataFrame({'userId':a[:,0],'movieId':a[:,1],'rating':a[:,2]})\n",
    "        dfTemp.to_parquet('dataCV3/df'+inteName(j)+'_fold_'+str(fold)+'.gzip', compression='gzip',index=False)\n",
    "        del dfTemp,a\n",
    "    \n",
    "    print(\"Creation of the large intervalles\")\n",
    "    for i in range(10,50,5):\n",
    "        listDF=list()\n",
    "        for j in range(5):\n",
    "            listDF.append(pd.read_parquet('dataCV3/df'+inteName(i+j)+'_fold_'+str(fold)+'.gzip'))\n",
    "        dfTemp=pd.concat(listDF)\n",
    "        dfTemp.to_parquet('dataCV3/df'+inteName2(i)+'_fold_'+str(fold)+'.gzip', compression='gzip',index=False)\n",
    "    \n",
    "    print(\"Creation of the intervalle sup500\")\n",
    "    listDF=list()\n",
    "    for i in range(50,800):\n",
    "        path='dataCV3/df'+inteName(i)+'_fold_'+str(fold)+'.gzip'\n",
    "        if os.path.exists(path):\n",
    "            listDF.append(pd.read_parquet(path))\n",
    "    dfTemp=pd.concat(listDF)\n",
    "    dfTemp.to_parquet('dataCV3/df'+inteName2(50)+'_fold_'+str(fold)+'.gzip', compression='gzip',index=False)\n",
    "    del dfTemp,listDF\n",
    "    \n",
    "    print(\"Creation of the intervalle inf20\")\n",
    "    df1=pd.read_parquet('dataCV3/df1-9'+'_fold_'+str(fold)+'.gzip')\n",
    "    df2=pd.read_parquet('dataCV3/df10-19'+'_fold_'+str(fold)+'.gzip')\n",
    "    dfInf20=pd.concat([df1,df2])\n",
    "    dfInf20.to_parquet('dataCV3/dfInf20'+'_fold_'+str(fold)+'.gzip', compression='gzip',index=False)\n",
    "    del df1,df2,dfInf20\n",
    "    \n",
    "    print(\"Creation of the intervalle sup20\")\n",
    "    listDF=list()\n",
    "    for i in range(2,10):\n",
    "        listDF.append(pd.read_parquet('dataCV3/df'+inteName2(i)+'_fold_'+str(fold)+'.gzip'))\n",
    "    for i in range(10,51,5):\n",
    "        listDF.append(pd.read_parquet('dataCV3/df'+inteName2(i)+'_fold_'+str(fold)+'.gzip'))\n",
    "    dfSup20=pd.concat(listDF)\n",
    "    dfSup20.to_parquet('dataCV3/dfSup20_fold_'+str(fold)+'.gzip', compression='gzip',index=False)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-  0  -\n",
      "-  1  -\n",
      "-  2  -\n",
      "-  3  -\n",
      "-  4  -\n",
      "-  5  -\n",
      "-  6  -\n",
      "-  7  -\n",
      "-  8  -\n",
      "-  9  -\n"
     ]
    }
   ],
   "source": [
    "for fold in range(10):\n",
    "    print('- ',fold,' -')\n",
    "    for i in range(10,800):\n",
    "        path='dataCV3/df'+inteName(i)+'_fold_'+str(fold)+'.gzip'\n",
    "        if os.path.exists(path):\n",
    "            os.remove(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
